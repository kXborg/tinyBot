{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d36617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795e0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config / hyperparameters\n",
    "DATA_CSV = \"../../dataset/tinybot_augmented_dataset.csv\"   # generated file\n",
    "VOCAB_SIZE = 8000        # tokenizer size (cap) - change if needed\n",
    "MAX_LEN = 20             # max tokens for input & output (pad/truncate)\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 192\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 150\n",
    "PATIENCE = 6\n",
    "TFLITE_PATH = \"tinybot_quantized.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4b11fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using columns: input_text , reply_text\n",
      "Tokenizer vocab size: 299 using vocab cap: 300\n",
      "Examples after filter: 15300\n"
     ]
    }
   ],
   "source": [
    "# 1) Load CSV\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "\n",
    "# handle various column names robustly\n",
    "user_col = next((c for c in df.columns if c.lower() in ('input_text','input','prompt','query')), df.columns[0])\n",
    "bot_col  = next((c for c in df.columns if c.lower() in ('reply_text','reply','response','output')), df.columns[1] if len(df.columns)>1 else df.columns[0])\n",
    "print(\"Using columns:\", user_col, \",\", bot_col)\n",
    "\n",
    "user_texts = df[user_col].astype(str).tolist()\n",
    "bot_texts_raw = df[bot_col].astype(str).tolist()\n",
    "\n",
    "\n",
    "# 2) Add start/end tokens and normalize\n",
    "\n",
    "def normalize(s):\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "user_texts = [normalize(t) for t in user_texts]\n",
    "bot_texts = [f\"start {normalize(t)} end\" for t in bot_texts_raw]\n",
    "\n",
    "\n",
    "# 3) Tokenize (single tokenizer for both)\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE, oov_token='UNK', filters=\"\")\n",
    "tokenizer.fit_on_texts(user_texts + bot_texts)\n",
    "word_index = tokenizer.word_index\n",
    "index_word = {v:k for k,v in word_index.items()}\n",
    "vocab_size = min(VOCAB_SIZE, len(word_index) + 1)\n",
    "print(\"Tokenizer vocab size:\", len(word_index), \"using vocab cap:\", vocab_size)\n",
    "\n",
    "# sequences\n",
    "input_seq = tokenizer.texts_to_sequences(user_texts)\n",
    "target_seq = tokenizer.texts_to_sequences(bot_texts)\n",
    "\n",
    "# pad/truncate\n",
    "input_seq = pad_sequences(input_seq, maxlen=MAX_LEN, padding='post')\n",
    "target_seq = pad_sequences(target_seq, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "# Discard examples where target has only 1 token (should be >= start + end)\n",
    "valid_idx = [i for i in range(len(target_seq)) if np.count_nonzero(target_seq[i]) > 1]\n",
    "input_seq = input_seq[valid_idx]\n",
    "target_seq = target_seq[valid_idx]\n",
    "print(\"Examples after filter:\", input_seq.shape[0])\n",
    "\n",
    "# teacher forcing slices\n",
    "decoder_input = target_seq[:, :-1]    # all but last\n",
    "decoder_target = target_seq[:, 1:]    # all but first\n",
    "decoder_target = np.expand_dims(decoder_target, -1)  # required for sparse loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd49a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_emb (Embedding)            (None, None, 128)    38400       ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " encoder_gru (GRU)              [(None, None, 192),  185472      ['enc_emb[0][0]']                \n",
      "                                 (None, 192)]                                                     \n",
      "                                                                                                  \n",
      " dec_emb (Embedding)            (None, None, 128)    38400       ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " enc_proj (Dense)               (None, None, 128)    24704       ['encoder_gru[0][0]']            \n",
      "                                                                                                  \n",
      " attention_layer (Attention)    (None, None, 128)    0           ['dec_emb[0][0]',                \n",
      "                                                                  'enc_proj[0][0]']               \n",
      "                                                                                                  \n",
      " dec_concat (Concatenate)       (None, None, 256)    0           ['dec_emb[0][0]',                \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_gru (GRU)              [(None, None, 192),  259200      ['dec_concat[0][0]',             \n",
      "                                 (None, 192)]                     'encoder_gru[0][1]']            \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)          (None, None, 300)    57900       ['decoder_gru[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 604,076\n",
      "Trainable params: 604,076\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 4) Build model: Seq2Seq + Attention\n",
    "\n",
    "# Encoder\n",
    "enc_inputs = keras.Input(shape=(None,), name=\"encoder_inputs\")\n",
    "enc_emb = layers.Embedding(vocab_size, EMBED_DIM, mask_zero=True, name=\"enc_emb\")(enc_inputs)\n",
    "enc_outputs, enc_state = layers.GRU(HIDDEN_DIM, return_sequences=True, return_state=True, name=\"encoder_gru\")(enc_emb)\n",
    "\n",
    "# Decoder\n",
    "dec_inputs = keras.Input(shape=(None,), name=\"decoder_inputs\")\n",
    "dec_emb_layer = layers.Embedding(vocab_size, EMBED_DIM, mask_zero=True, name=\"dec_emb\")\n",
    "dec_emb = dec_emb_layer(dec_inputs)\n",
    "\n",
    "# Project encoder outputs to embedding dim (so Attention queries/values match)\n",
    "enc_proj = layers.Dense(EMBED_DIM, name=\"enc_proj\")(enc_outputs)\n",
    "\n",
    "# Attention (Keras Attention expects same last dim for query/value)\n",
    "attn = layers.Attention(name=\"attention_layer\")\n",
    "# combine decoder embeddings and context at each time step:\n",
    "# We'll compute context for each decoder time step by using Attention(dec_emb, enc_proj)\n",
    "context = attn([dec_emb, enc_proj])   # shape: (batch, dec_time, EMBED_DIM)\n",
    "decoder_combined = layers.Concatenate(axis=-1, name=\"dec_concat\")([dec_emb, context])\n",
    "\n",
    "decoder_gru = layers.GRU(HIDDEN_DIM, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "dec_outputs, _ = decoder_gru(decoder_combined, initial_state=enc_state)\n",
    "decoder_dense = layers.Dense(vocab_size, activation=\"softmax\", name=\"decoder_dense\")\n",
    "decoder_outputs = decoder_dense(dec_outputs)\n",
    "\n",
    "model = keras.Model([enc_inputs, dec_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7caef625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "216/216 [==============================] - 11s 20ms/step - loss: 0.9558 - accuracy: 0.5223 - val_loss: 3.1875 - val_accuracy: 0.3603\n",
      "Epoch 2/150\n",
      "216/216 [==============================] - 3s 13ms/step - loss: 0.2866 - accuracy: 0.8006 - val_loss: 3.5640 - val_accuracy: 0.3859\n",
      "Epoch 3/150\n",
      "216/216 [==============================] - 3s 12ms/step - loss: 0.2028 - accuracy: 0.8445 - val_loss: 3.7723 - val_accuracy: 0.3859\n",
      "Epoch 4/150\n",
      "216/216 [==============================] - 3s 12ms/step - loss: 0.1293 - accuracy: 0.8906 - val_loss: 3.9285 - val_accuracy: 0.3859\n",
      "Epoch 5/150\n",
      "216/216 [==============================] - 3s 12ms/step - loss: 0.1085 - accuracy: 0.8942 - val_loss: 3.9902 - val_accuracy: 0.3859\n",
      "Epoch 6/150\n",
      "216/216 [==============================] - 3s 12ms/step - loss: 0.1037 - accuracy: 0.8942 - val_loss: 4.1854 - val_accuracy: 0.3975\n",
      "Epoch 7/150\n",
      "216/216 [==============================] - 3s 12ms/step - loss: 0.1019 - accuracy: 0.8954 - val_loss: 4.1225 - val_accuracy: 0.3859\n",
      "Saved: tinybot_attn_final.h5 and tokenizer.pkl\n"
     ]
    }
   ],
   "source": [
    "# Callbacks: checkpoints & early stopping\n",
    "\n",
    "ckpt_path = \"tiny_bot_attn.h5\"\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(ckpt_path, save_best_only=True, monitor='val_loss'),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "\n",
    "# Train / fine-tune\n",
    "history = model.fit(\n",
    "    [input_seq, decoder_input],\n",
    "    decoder_target,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Save model + tokenizer\n",
    "model.save(\"tinybot_attn_final.h5\")\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(\"Saved: tinybot_attn_final.h5 and tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e032b1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi -> Bot: setting quiet mode and dimming lights 😴\n",
      "User: What can you do? -> Bot: welcome home! turning on your favorite lights 🏠\n",
      "User: Turn on the light -> Bot: got it! powering down the heater 💡\n",
      "User: It's too hot -> Bot: switching on the lights 💡\n",
      "User: Is the fridge on? -> Bot: got it! powering down the moment.\n"
     ]
    }
   ],
   "source": [
    "# 8) Inference helper (greedy generation)\n",
    "reverse_word_index = {v:k for k,v in tokenizer.word_index.items()}\n",
    "\n",
    "def generate_reply_greedy(input_text, max_len=18):\n",
    "    s = normalize(input_text)\n",
    "    seq_in = tokenizer.texts_to_sequences([s])\n",
    "    seq_in = pad_sequences(seq_in, maxlen=MAX_LEN, padding='post')\n",
    "    # initial decoder token = 'start' if present in tokenizer, else use most common substitute\n",
    "    start_token = tokenizer.word_index.get(\"start\", tokenizer.word_index.get(\"START\", None))\n",
    "    end_token = tokenizer.word_index.get(\"end\", tokenizer.word_index.get(\"END\", None))\n",
    "    if start_token is None or end_token is None:\n",
    "        # fallback: use index 1 as start if not found\n",
    "        start_token = 1\n",
    "    dec_seq = [start_token]\n",
    "    for i in range(max_len):\n",
    "        dec_input = pad_sequences([dec_seq], maxlen=MAX_LEN-1, padding='post')  # decoder_input length = MAX_LEN-1 used at training\n",
    "        preds = model.predict([seq_in, dec_input], verbose=0)\n",
    "        # take the probability distribution at current time step (= len(dec_seq)-1)\n",
    "        tpos = min(len(dec_seq)-1, preds.shape[1]-1)\n",
    "        next_id = int(np.argmax(preds[0, tpos]))\n",
    "        dec_seq.append(next_id)\n",
    "        if end_token is not None and next_id == end_token:\n",
    "            break\n",
    "    # convert to words, remove start/end\n",
    "    words = [reverse_word_index.get(i, \"\") for i in dec_seq if i>0]\n",
    "    # strip start/end tokens if present in text\n",
    "    words = [w for w in words if w not in (\"start\",\"end\",\"START\",\"END\")]\n",
    "    return \" \".join(words).strip()\n",
    "\n",
    "# quick sanity test (use a few examples)\n",
    "tests = [\"Hi\", \"What can you do?\", \"Turn on the light\", \"It's too hot\", \"Is the fridge on?\"]\n",
    "for t in tests:\n",
    "    print(\"User:\", t, \"-> Bot:\", generate_reply_greedy(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0276613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Convert to quantized TFLite (full integer, representative dataset)\n",
    "# Create representative dataset generator for calibration\n",
    "def rep_gen():\n",
    "    for i in range(1000):\n",
    "        idx = random.randint(0, input_seq.shape[0]-1)\n",
    "        yield [np.array([input_seq[idx]], dtype=np.int32), np.array([decoder_input[idx]], dtype=np.int32)]\n",
    "\n",
    "# Convert\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Set optimizations and supported ops\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = rep_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set input/output type to int8\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "try:\n",
    "    tflite_model = converter.convert()\n",
    "    with open(TFLITE_PATH, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "    print(\"Saved quantized TFLite:\", TFLITE_PATH)\n",
    "except Exception as e:\n",
    "    print(\"TFLite conversion failed:\", e)\n",
    "    # If INT8 conversion fails on complex ops, try float16 minimal conversion:\n",
    "    try:\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "        tflite_model = converter.convert()\n",
    "        with open(\"tinybot_float32.tflite\",\"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "        print(\"Saved fallback float tflite: tinybot_float32.tflite\")\n",
    "    except Exception as e2:\n",
    "        print(\"Fallback tflite conversion also failed:\", e2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
